<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Robotik - Mechanical Eyes</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Place favicon.ico and apple-touch-icon.png in the root directory -->

        <link rel="stylesheet" href="css/normalize.css">
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <link rel="stylesheet" href="css/pygments.css">
        <link rel="stylesheet" href="css/main.css">
        <link rel="stylesheet" href="css/custom.css">
        <script src="js/vendor/modernizr-2.6.2.min.js"></script>
    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
        <![endif]-->

        <!-- Add your site or application content here -->
        <main>
            <section id="landingpage">
                <img src="img/start.jpg" id="start">
                <a href="#software" class="bullseye" id="bullseye_software" title="Software"></a>
                <a href="#hardware" class="bullseye" id="bullseye_hardware" title="Hardware"></a>
                <a href="#video" class="bullseye" id="bullseye_video" title="Video Processing"></a>
                <a href="#servo" class="bullseye" id="bullseye_servo" title="Servo Steuerung"></a>
                <a href="#probleme" class="bullseye" id="bullseye_probleme" title="Probleme"></a>
				<a href="#planung" class="bullseye" id="bullseye_planung" title="Planung"></a>
                <a href="#team" class="bullseye" id="bullseye_team" title="Das Team"></a>
                <a href="#downloads" class="bullseye" id="bullseye_downloads" title="Downloads"></a>
            </section>

            <section id="software" class="subpage markdown-format">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_software">&lt; Zur&uuml;ck</a>
                <h2>Eingesetzte Software</h2>
                <ul class="software_list">
                    <li>Arch Linux ARM f&uuml;r Raspberry Pi (ARMv6) <a href="http://archlinuxarm.org/platforms/armv6/raspberry-pi">http://archlinuxarm.org/platforms/armv6/raspberry-pi</a></li>
                    <li>OpenCV 2.4 <a href="http://opencv.org/">http://opencv.org/</a></li>
                    <li>ServoBlaster <a href="https://github.com/richardghirst/PiBits/tree/master/ServoBlaster">https://github.com/richardghirst/PiBits/tree/master/ServoBlaster</a></li>
                    <li>raspicam 0.0.5 <a href="http://sourceforge.net/projects/raspicam/">http://sourceforge.net/projects/raspicam/</a></li>
                    <li>mechanical eyes (entwickelt im Verlauf dieses Projekts) <a href="https://github.com/bluec0re/mechanical_eyes">https://github.com/bluec0re/mechanical_eyes</a></li>
                </ul>

                <h2>Implementierung</h2>
                Die Implementierung ist aufgeteilt in eine Bibliothek zur Video Analyse, einem Programm zum testen der Kalibrierung und dem eigentlichen
                Programm welches auf Personen im Bild reagiert und die Servos ansteuert. Die Unterteilung wurde durchgef&uuml;hrt um den Kompilationsaufwand auf dem Raspberry Pi zu minimieren.

                <h3>PersonTracker</h3>
                PersonTracker ist die Bibliothek welche die Bilder von der Raspberry Pi Kamera abruft, je nach gew&auml;hlter Variante
                analysiert (Details im Abschnitt Video Processing). Die Bibliothek liefert die prozentuale Position (Werte zwischen 0 und 1) des gefundenen Gesichtes im Bild.
                Die Konfiguration des Haarcascades Algorithmus kann &uuml;ber die Datei settings.ini erfolgen.
                <br/>
                PersonTracker liefert ein eigenes Programm (tracker_standalone) mit, welches ein Testen der gew&auml;hlten Paramerter erlaubt.
                Dabei werden 2 Bilder generiert (faces.png und persons.png) welche das Ergebnis der Verarbeitung darstellen.

                <h3>Mechanical Eyes</h3>
                Mechanical Eyes ist das Hauptprogramm welches die Ergebnisse der Gesichtserkennung interpretiert und die Servos
                dementsprechend steuert. Auch hier kann die Feineinstellung der Servos &uuml;ber die Konfigurationsdatei erfolgen.

                <h2>Installationsanleitung</h2>
                <ol>
                    <li>Installiere cmake</li>
                    <li>Installiere opencv</li>
                    <li>Installiere mmal (meistens bereits in der Raspi Firmware enthalten [raspberrypi-firmware-tools])</li>
                    <li>Buildprozess servoblaster
                        <code class="command-line">
                            <span class="command">git clone https://github.com/richardghirst/PiBits</span>
                            <span class="command">cd PiBits/ServoBlaster/user</span>
                            <span class="command">make</span>
                        </code>
                        Optional auf dem raspbian OS (triggert Autostart beim Boot):
                        <code class="command-line">
                            <span class="command">make install</span>
                        </code>
                    </li>
                    <li>Buildprozess raspicam
                        <code class="command-line">
                            <span class="command">cd &lt;mechanical_eyes dir&gt;/libs/raspicam-0.0.5/</span>
                            <span class="command">mkdir build && cd build</span>
                            <span class="command">cmake ..</span>
                            <span class="command">make && make install</span>
                        </code>
                    </li>
                    <li>Buildprozess mechanical_eyes
                        <code class="command-line">
                            <span class="command">cd &lt;mechanical_eyes dir&gt;</span>
                            <span class="command">mkdir build && cd build</span>
                            <span class="command">cmake ..</span>
                            <span class="command">make && make install</span>
                        </code>
                    </li>
                </ol>

                <h2>Konfiguration</h2>
                Die folgende Beispielkonfiguration wird in <i>/etc/mechanical_eyes/settings.ini</i> installiert. Diese
                Konfiguration stellt eine funktionierende Variante mit der aktuellen Hardware Konstellation dar.
                <br>
                Die jeweilige Erkl&auml;hrung f&uuml;r die einzelnen Parameters ist mit Kommentaren versehen.
                <div class="highlight"><pre><span class="c1">; settings for the video recording</span>
<span class="k">[persontracker]</span>
<span class="c1">; image width (default: 640)</span>
<span class="na">width</span> <span class="o">=</span> <span class="s">320</span>
<span class="c1">; image height (default: 480)</span>
<span class="na">height</span> <span class="o">=</span> <span class="s">240</span>
<span class="c1">; brightness value (0-100) (default: 50)</span>
<span class="na">brightness</span> <span class="o">=</span> <span class="s">55</span>
<span class="c1">; contrast value (0-100) (default: 50)</span>
<span class="na">contrast</span> <span class="o">=</span> <span class="s">50</span>
<span class="c1">; saturation value (0-100) (default: 50)</span>
<span class="na">saturation</span> <span class="o">=</span> <span class="s">50</span>
<span class="c1">; gain value (0-100) (default: 50)</span>
<span class="na">gain</span> <span class="o">=</span> <span class="s">50</span>
<span class="c1">; flips the image vertically (default: false)</span>
<span class="na">flip_vertical</span> <span class="o">=</span> <span class="s">true</span>
<span class="c1">; flips the image horizontally (default: false)</span>
<span class="na">flip_horizontal</span> <span class="o">=</span> <span class="s">false</span>

<span class="c1">; settings for the face detection (settings for http://docs.opencv.org/modules/objdetect/doc/cascade_classification.html#cascadeclassifier-detectmultiscale)</span>
<span class="k">[persontracker-face]</span>
<span class="na">scalefactor</span> <span class="o">=</span> <span class="s">1.1</span>
<span class="na">minneighbors</span> <span class="o">=</span> <span class="s">4</span>
<span class="na">flags</span> <span class="o">=</span> <span class="s">6</span>
<span class="na">minsize_x</span> <span class="o">=</span> <span class="s">20</span>
<span class="na">minsize_y</span> <span class="o">=</span> <span class="s">20</span>
<span class="na">maxsize_x</span> <span class="o">=</span> <span class="s">0</span>
<span class="na">maxsize_y</span> <span class="o">=</span> <span class="s">0</span>

<span class="c1">; servo settings</span>
<span class="k">[mechanical_eyes]</span>
<span class="c1">; servo id for vertical control, left side</span>
<span class="na">servo_vertical_left</span> <span class="o">=</span> <span class="s">0</span>
<span class="c1">; minimal allowed servo value</span>
<span class="na">servo_vertical_left_min</span> <span class="o">=</span> <span class="s">110</span>
<span class="c1">; maxium allowed servo value</span>
<span class="na">servo_vertical_left_max</span> <span class="o">=</span> <span class="s">200</span>
<span class="c1">; scaling of the percentage value (max-min)*percentage*scale</span>
<span class="na">servo_vertical_left_scale</span> <span class="o">=</span> <span class="s">-1.0</span>

<span class="c1">; servo id for vertical control, right side (not used at the moment)</span>
<span class="c1">;servo_vertical_right = </span>
<span class="c1">;servo_vertical_right_min = 80</span>
<span class="c1">;servo_vertical_right_max = 130</span>
<span class="c1">;servo_vertical_right_scale = 1.0</span>

<span class="c1">; servo id for horizontal control, left side</span>
<span class="na">servo_horizontal_left</span> <span class="o">=</span> <span class="s">1</span>
<span class="na">servo_horizontal_left_min</span> <span class="o">=</span> <span class="s">80</span>
<span class="na">servo_horizontal_left_max</span> <span class="o">=</span> <span class="s">200</span>
<span class="na">servo_horizontal_left_scale</span> <span class="o">=</span> <span class="s">-1.0</span>

<span class="c1">; servo id for horizontal control, right side</span>
<span class="na">servo_horizontal_right</span> <span class="o">=</span> <span class="s">4</span>
<span class="na">servo_horizontal_right_min</span> <span class="o">=</span> <span class="s">80</span>
<span class="na">servo_horizontal_right_max</span> <span class="o">=</span> <span class="s">200</span>
<span class="na">servo_horizontal_right_scale</span> <span class="o">=</span> <span class="s">-1.0</span>
</pre></div>
                Die Nummerierung der Servos kann man &uuml;ber das device servoblaster-cfg abrufen:

                <code class="command-line">
                    <span class="command">cat /dev/servoblaster-cfg</span>
                </code>
            </section>

            <section id="video" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_video">&lt; Zur&uuml;ck</a>
                <h2>Video Processing</h2>
                Zur Erkennung von Personen im aufgezeichneten Bild wird die Grafikbibliothek OpenCV verwendet.
                Dazu wird das Bild zun&auml;chst vorverarbeitet um Fehlerquellen wie Lichtverh&auml;ltnisse m&ouml;glichst
                klein zu halten. Die Vorverarbeitung beinhaltet neben der Umwandlung in ein Schwarz-Wei&szlig;-Bild die
                anschlie&szlig;ende normalisierung der Farbwerte. Dabei wird das Helligkeitsspektrum auf Werte zwischen
                0 und 255 gestreckt. Das resultierende Bild erm&ouml;glicht es leichter Helligkeitsabstufungen zu erkennen.
                Auf ein smoothing zur Rauschunterdr&uuml;ckung wurde explizit verzichtet um die Rechenlast f&uuml;r den
                Raspberry Pi m&ouml;glichst klein zu halten.
                <br/>
                Die eigentliche Erkennung erfolgt mit dem HaarCascade Algorithmus. Dazu werden Helligkeitsdifferenzen
                anhand von zuvor trainierten Modellen im Bild gesucht.
                <div style="text-align: center">
                    <img src="img/haar.png" alt="no-pic" />
                    <div class="caption">Beispiel Erkennnung von Haarcascades (Bild von opencv.org)</div>
                </div>
                <br/>
                Das Resultat bei einem erfolgreich gefundenen Gesicht ist im folgenden Bild zu erkennen:
                <div style="text-align: center">
    				<img src="img/faces.png" alt="no-pic" />
                    <div class="caption">Gesichtserkennung</div>
                </div>
                Ein weiterer Ansatz war die Erkennung von Personen anstelle von Gesichtern. Dazu wurde ein HOG Detektor (<a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">Wikipedia</a>)
                verwendet. Nach einer erkannten Person wurde die Position des Gesichts nach dem goldenen Schnitt gesch&auuml;tzt.
                Da dieser Ansatz jedoch zu rechenlastig war, wurde dieser im endg&uuml;ltigen Programm nicht mehr verwendet.
            </section>

            <section id="servo" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_servo">&lt; Zur&uuml;ck</a>
                <h2>Servo Steuerung</h2>
                Die Servos werden &uuml;ber die GPIO Pins des Raspberry Pi angesteuert. Dazu erfolgt eine Pulsweitenmodulation
                (PWM) durch den Linux Kernel mit Servoblaster als Middleware. Wie im folgenden Bild dargestellt wird die
                Servoposition anhand der Dauer der Signale eingestellt.

                <div style="text-align: center">
                    <img src="img/servosignal.jpg">
                    <div class="caption">PWM Servosignal (<a href="http://www.erkenntnishorizont.de/images/robotik/servosignal.jpg">Quelle</a>)</div>
                </div>

                <h2>Setup</h2>
                Der Anschluss der Servos erfolgt mit einem zus&auml;tzlichen Battery Pack um die Stromlast f&uuml;r den
                Raspberry Pi zu verringern. Das Setup ist f&uuml;r einen Servo beispielhaft im folgenden Bild zu erkennen.


                <div style="text-align: center">
                    <img src="img/servo_setup.png">
                    <div class="caption">Servo Setup</div>
                </div>
            </section>

            <section id="hardware" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_hardware">&lt; Zur&uuml;ck</a>
				<h2>Verwendete Materialien</h2>
				<ul>
					<li>Aluminium Profil 2,5cm x 1,5cm</li>
					<li>Sperrholzplatten</li>
					<li>Siphonrohr 5cm Durchmesser</li>
					<li>Tischtennisbälle</li>
					<li>Schrauben</li>
					<li>Büroklammern (Federstahl)</li>
					<li>Raspberry Pi</li>
					<li>Breakout Board</li>
					<li>Modellbau Steckverbindungen</li>
					<li>Batteriepack (inkl. 4 AA Batterien)</li>
				</ul>
				<h2>Aufbau</h2>
				<ol>
					<li>...</li>
				</ol>
            </section>

			<section id="team" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_team">&lt; Zur&uuml;ck</a>
				<h2>Team</h2>
				<div style="text-align: center">
					<img src="img/team.png" alt="Team" />
                    <div class="caption">Kevin Schaller und Timo Schmid</div>
				</div>
            </section>

			<section id="probleme" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_probleme">&lt; Zur&uuml;ck</a>
				<h2>Probleme</h2>

                <h3>Software</h3>
                <ul>
                    <li>
                        Der Raspberry Pi besitzt zwar eine Hardware Decodierung von h264 Videodaten, jedoch reichen sein 800 Mhz BCM2835
                        Prozessor und der 512 MB gro&szlig;e RAM nur begrenzt f&uuml;r gr&ouml;&szlig;ere Bildverarbeitungsprojekte.
                        <ul>
                            <li>Wenig verbesserungspotential au&szlig;er Parametertuning der Algorithmen</li>
                        </ul>
                    </li>
                    <li>
                        Die Software PWM ist nicht echtzeitf&auml;hig, wodurch die gleichzeitige Ansteuerung der Servos
                        beeintr&auml;chtigt ist.
                        <ul>
                            <li>
                                M&ouml;gliche L&ouml;sung k&ouml;nnte der Umstieg auf Hardware PWM oder ein
                                echtzeitf&auml;higes Ger&auml;t sein.
                            </li>
                        </ul>
                    </li>
                </ul>

                <h3>Hardware</h3>
                <ul>
                    <li>
                        Die Raspberry Pi Kamera bietet ohne eine zus&auml;tzliche Linse nur einen begrenzten Field of View
                        (zB. 2.0mx1.33m bei 2m Entfernung und 16:10 Seitenverh&auml;tnis).
                        <ul>
                            <li>
                                Die Verwendung einer Linse f&uuml;r das Kameramodul k&ouml;nnte eine m&ouml;gliche
                                L&ouml;sung darstellen.
                            </li>
                        </ul>
                    </li>
                    <li>
                        Der Raspberry Pi besitzt nur einen Hardware PWM Pin (GPIO 18). Damit musste auf Software PWM
                        ausgewichen werden um mehr als einen Servo anzusprechen.
                        <ul>
                            <li>
                                M&ouml;gliche L&ouml;sung k&ouml;nnte der Anschluss eines gesonderten Boards zur
                                Servosteuerung sein.
                            </li>
                        </ul>
                    </li>
                    <li>
                        Die Servos ben&ouml;tigen mehr Strom als der Raspberry Pi &uuml;ber seine GPIO Pins liefern kann.
                        Dies f&uuml;hrte zu tempor&auml;ren (Raspberry Pi war nicht mehr erreichbar solange die Servos
                        angesteuert wurden) und permanenten (kompletter Absturz des Raspberry Pi) Problemen in der
                        Nutzung
                        <ul>
                            <li>
                                Durch hinzuf&uuml;gen eines zus&auml;tzlichen Batterypacks konnte die Stromzufuhr f&uuml;r
                                die Servos ausgelagert werden.
                            </li>
                        </ul>
                    </li>
                </ul>
            </section>

			<section id="downloads" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_downloads">&lt; Zur&uuml;ck</a>
				<h2>Downloads</h2>
				<ul>
					<li><a href="downloads/projektplan_mechanische_augen.pdf">Projektplan</a></li>
					<li><a href="downloads/poster_mechanische_augen.pdf">Poster</a></li>
                    <li><a href="https://github.com/bluec0re/mechanical_eyes">Source code (auf github)</a></li>
				</ul>
            </section>

			<section id="planung" class="subpage">
                <a href="#landingpage" class="btn btn-default btn-lg" role="button" id="back_planung">&lt; Zur&uuml;ck</a>
				<h2>Aufgabenstellung und Planung</h2>
                Aufgabe war die Planung und Umsetzung eines Roboters, welcher mithilfe eines Raspberry Pis und Kamera
                Personen mit seinen Augen verfolgen kann.
            </section>

            <!-- github ribbon -->
            <a href="https://github.com/bluec0re/mechanical_eyes"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>
        </main>

        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.2.min.js"><\/script>')</script>
        <script src="js/bootstrap.min.js"></script>
        <script src="js/plugins.js"></script>
        <script src="js/main.js"></script>
    </body>
</html>
                        
